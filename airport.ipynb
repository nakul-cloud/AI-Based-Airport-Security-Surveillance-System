{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826a90f3-5c82-46bb-85d8-a59f1bc5a4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting filterpy\n",
      "  Downloading filterpy-1.4.5.zip (177 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in g:\\anaconda\\lib\\site-packages (from filterpy) (2.1.3)\n",
      "Requirement already satisfied: scipy in g:\\anaconda\\lib\\site-packages (from filterpy) (1.15.3)\n",
      "Requirement already satisfied: matplotlib in g:\\anaconda\\lib\\site-packages (from filterpy) (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in g:\\anaconda\\lib\\site-packages (from matplotlib->filterpy) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in g:\\anaconda\\lib\\site-packages (from matplotlib->filterpy) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in g:\\anaconda\\lib\\site-packages (from matplotlib->filterpy) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in g:\\anaconda\\lib\\site-packages (from matplotlib->filterpy) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in g:\\anaconda\\lib\\site-packages (from matplotlib->filterpy) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in g:\\anaconda\\lib\\site-packages (from matplotlib->filterpy) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in g:\\anaconda\\lib\\site-packages (from matplotlib->filterpy) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in g:\\anaconda\\lib\\site-packages (from matplotlib->filterpy) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in g:\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.17.0)\n",
      "Building wheels for collected packages: filterpy\n",
      "  Building wheel for filterpy (setup.py): started\n",
      "  Building wheel for filterpy (setup.py): finished with status 'done'\n",
      "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110541 sha256=8ef2c24b2d78e9d0c5dacb50eb81955b7c7aca48e1653cc49fc7b4dd669d9203\n",
      "  Stored in directory: c:\\users\\nakul\\appdata\\local\\pip\\cache\\wheels\\79\\33\\43\\53b597b8f63de80842202a5fed633eea6f5ce3e3f6c6efbab8\n",
      "Successfully built filterpy\n",
      "Installing collected packages: filterpy\n",
      "Successfully installed filterpy-1.4.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'filterpy' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'filterpy'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "pip install filterpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d92280-6781-4e24-ab79-45c77cdd79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import defaultdict, deque\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "from datetime import datetime\n",
    "from scipy.spatial import distance\n",
    "from filterpy.kalman import KalmanFilter\n",
    "import os\n",
    "from IPython.display import clear_output, Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c10109dc-260a-4c6d-9388-f337f5d29049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded!\n",
      "Video: airport footage.mp4\n",
      "Model: yolov8n.pt\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# CONFIGURATION\n",
    "# ================================\n",
    "\n",
    "CONFIG = {\n",
    "    # Video Input\n",
    "    'VIDEO_PATH': 'airport footage.mp4',  # Change to your video path\n",
    "    'OUTPUT_PATH': 'output_video.mp4',\n",
    "    'DISPLAY_WIDTH': 1280,  # Display width in notebook\n",
    "    \n",
    "    # Detection Settings\n",
    "    'MODEL': 'yolov8n.pt',  # Will auto-download on first run\n",
    "    'CONFIDENCE_THRESHOLD': 0.5,\n",
    "    'PERSON_CLASS': 0,\n",
    "    'LUGGAGE_CLASSES': [24, 28, 26],  # backpack, suitcase, handbag\n",
    "    \n",
    "    # Tracking Settings\n",
    "    'MAX_AGE': 30,  # Frames to keep lost tracks\n",
    "    'MIN_HITS': 3,   # Frames to confirm track\n",
    "    'IOU_THRESHOLD': 0.3,\n",
    "    \n",
    "    # Crowd Density\n",
    "    'GRID_SIZE': (5, 5),  # Divide frame into grid\n",
    "    'DENSITY_CRITICAL': 1.0,  # persons/m¬≤\n",
    "    'PIXELS_PER_METER': 50,   # Calibration (adjust for your camera)\n",
    "    \n",
    "    # Abandoned Luggage Detection\n",
    "    'OWNER_DISTANCE_THRESHOLD': 150,  # pixels (‚âà5 meters)\n",
    "    'STATIONARY_TIME': 30,  # seconds (30 frames at 1 FPS check)\n",
    "    'MIN_LUGGAGE_SIZE': 20,  # pixels\n",
    "    \n",
    "    # Optical Flow\n",
    "    'ENABLE_OPTICAL_FLOW': True,\n",
    "    'FLOW_THRESHOLD_LOW': 0.5,  # Bottleneck detection\n",
    "    'FLOW_THRESHOLD_HIGH': 3.0,  # Panic detection\n",
    "    \n",
    "    # Display\n",
    "    'SHOW_BBOXES': True,\n",
    "    'SHOW_TRAJECTORIES': True,\n",
    "    'SHOW_HEATMAP': True,\n",
    "    'SHOW_FLOW': True,\n",
    "    'PROCESS_EVERY_N_FRAMES': 1,  # Process every N frames (1=all frames)\n",
    "}\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('output', exist_ok=True)\n",
    "os.makedirs('output/alerts', exist_ok=True)\n",
    "\n",
    "print(\"Configuration loaded!\")\n",
    "print(f\"Video: {CONFIG['VIDEO_PATH']}\")\n",
    "print(f\"Model: {CONFIG['MODEL']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c9e35c5-f352-41d7-af9a-d460f40d8129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined!\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# HELPER FUNCTIONS\n",
    "# ================================\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"Compute Intersection over Union\"\"\"\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1_, y1_, x2_, y2_ = box2\n",
    "    \n",
    "    xi1 = max(x1, x1_)\n",
    "    yi1 = max(y1, y1_)\n",
    "    xi2 = min(x2, x2_)\n",
    "    yi2 = min(y2, y2_)\n",
    "    \n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x2_ - x1_) * (y2_ - y1_)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "def get_center(bbox):\n",
    "    \"\"\"Get center point of bounding box\"\"\"\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    return (int((x1 + x2) / 2), int((y1 + y2) / 2))\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"Calculate Euclidean distance between two points\"\"\"\n",
    "    return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)\n",
    "\n",
    "def draw_text_with_background(img, text, position, font_scale=0.6, thickness=2, \n",
    "                               text_color=(255, 255, 255), bg_color=(0, 0, 0)):\n",
    "    \"\"\"Draw text with background for better visibility\"\"\"\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "    \n",
    "    x, y = position\n",
    "    cv2.rectangle(img, (x, y - text_height - baseline), \n",
    "                  (x + text_width, y + baseline), bg_color, -1)\n",
    "    cv2.putText(img, text, (x, y), font, font_scale, text_color, thickness)\n",
    "\n",
    "def apply_colormap_to_heatmap(heatmap):\n",
    "    \"\"\"Apply color mapping to heatmap\"\"\"\n",
    "    normalized = cv2.normalize(heatmap, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    colored = cv2.applyColorMap(normalized.astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    return colored\n",
    "\n",
    "print(\"Helper functions defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b05a3889-4f8c-47de-ab9d-8012bea7fcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tracker class defined!\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# SIMPLE TRACKER (ByteTrack-style)\n",
    "# ================================\n",
    "\n",
    "class SimpleTracker:\n",
    "    \"\"\"Simple multi-object tracker\"\"\"\n",
    "    \n",
    "    def __init__(self, max_age=30, min_hits=3, iou_threshold=0.3):\n",
    "        self.max_age = max_age\n",
    "        self.min_hits = min_hits\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.tracks = {}\n",
    "        self.next_id = 1\n",
    "        self.frame_count = 0\n",
    "        \n",
    "    def update(self, detections):\n",
    "        \"\"\"\n",
    "        Update tracker with new detections\n",
    "        \n",
    "        Args:\n",
    "            detections: List of [x1, y1, x2, y2, confidence, class_id]\n",
    "        \n",
    "        Returns:\n",
    "            List of active tracks: [(track_id, bbox, class_id), ...]\n",
    "        \"\"\"\n",
    "        self.frame_count += 1\n",
    "        \n",
    "        # If no existing tracks, create new ones\n",
    "        if not self.tracks:\n",
    "            for det in detections:\n",
    "                self.tracks[self.next_id] = {\n",
    "                    'bbox': det[:4],\n",
    "                    'class': int(det[5]),\n",
    "                    'hits': 1,\n",
    "                    'age': 0,\n",
    "                    'last_seen': self.frame_count\n",
    "                }\n",
    "                self.next_id += 1\n",
    "            return [(tid, track['bbox'], track['class']) \n",
    "                    for tid, track in self.tracks.items()]\n",
    "        \n",
    "        # Match detections to existing tracks using IoU\n",
    "        matched = set()\n",
    "        new_detections = []\n",
    "        \n",
    "        for det in detections:\n",
    "            best_iou = 0\n",
    "            best_track_id = None\n",
    "            \n",
    "            for track_id, track in self.tracks.items():\n",
    "                if track_id in matched:\n",
    "                    continue\n",
    "                iou = compute_iou(det[:4], track['bbox'])\n",
    "                if iou > self.iou_threshold and iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_track_id = track_id\n",
    "            \n",
    "            if best_track_id is not None:\n",
    "                # Update existing track\n",
    "                self.tracks[best_track_id]['bbox'] = det[:4]\n",
    "                self.tracks[best_track_id]['hits'] += 1\n",
    "                self.tracks[best_track_id]['age'] = 0\n",
    "                self.tracks[best_track_id]['last_seen'] = self.frame_count\n",
    "                matched.add(best_track_id)\n",
    "            else:\n",
    "                # New detection\n",
    "                new_detections.append(det)\n",
    "        \n",
    "        # Create new tracks for unmatched detections\n",
    "        for det in new_detections:\n",
    "            self.tracks[self.next_id] = {\n",
    "                'bbox': det[:4],\n",
    "                'class': int(det[5]),\n",
    "                'hits': 1,\n",
    "                'age': 0,\n",
    "                'last_seen': self.frame_count\n",
    "            }\n",
    "            self.next_id += 1\n",
    "        \n",
    "        # Age unmatched tracks\n",
    "        tracks_to_remove = []\n",
    "        for track_id, track in self.tracks.items():\n",
    "            if track_id not in matched:\n",
    "                track['age'] += 1\n",
    "                if track['age'] > self.max_age:\n",
    "                    tracks_to_remove.append(track_id)\n",
    "        \n",
    "        # Remove old tracks\n",
    "        for track_id in tracks_to_remove:\n",
    "            del self.tracks[track_id]\n",
    "        \n",
    "        # Return active tracks (with minimum hits)\n",
    "        active_tracks = []\n",
    "        for track_id, track in self.tracks.items():\n",
    "            if track['hits'] >= self.min_hits:\n",
    "                active_tracks.append((track_id, track['bbox'], track['class']))\n",
    "        \n",
    "        return active_tracks\n",
    "\n",
    "print(\"‚úÖ Tracker class defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0345aad0-23b6-477e-b695-0620b90c61a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Crowd density analyzer defined!\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# CROWD DENSITY ANALYZER\n",
    "# ================================\n",
    "\n",
    "class CrowdDensityAnalyzer:\n",
    "    \"\"\"Analyze crowd density and movement\"\"\"\n",
    "    \n",
    "    def __init__(self, frame_shape, grid_size=(5, 5), pixels_per_meter=50):\n",
    "        self.frame_height, self.frame_width = frame_shape[:2]\n",
    "        self.grid_rows, self.grid_cols = grid_size\n",
    "        self.pixels_per_meter = pixels_per_meter\n",
    "        \n",
    "        # Calculate grid cell dimensions\n",
    "        self.cell_height = self.frame_height // self.grid_rows\n",
    "        self.cell_width = self.frame_width // self.grid_cols\n",
    "        \n",
    "        # Occupancy grid for heatmap\n",
    "        self.occupancy_grid = np.zeros((self.grid_rows, self.grid_cols), dtype=np.float32)\n",
    "        \n",
    "        # Previous frame for optical flow\n",
    "        self.prev_gray = None\n",
    "        \n",
    "        print(f\"üìä Grid initialized: {self.grid_rows}x{self.grid_cols}\")\n",
    "        print(f\"üìè Cell size: {self.cell_width}x{self.cell_height} pixels\")\n",
    "    \n",
    "    def update_density(self, person_centers):\n",
    "        \"\"\"Update density grid with person positions\"\"\"\n",
    "        # Accumulate positions in grid cells\n",
    "        for cx, cy in person_centers:\n",
    "            grid_x = min(int(cx / self.cell_width), self.grid_cols - 1)\n",
    "            grid_y = min(int(cy / self.cell_height), self.grid_rows - 1)\n",
    "            self.occupancy_grid[grid_y, grid_x] += 1\n",
    "    \n",
    "    def get_density_heatmap(self, frame_shape):\n",
    "        \"\"\"Generate density heatmap\"\"\"\n",
    "        # Resize grid to frame size\n",
    "        heatmap = cv2.resize(self.occupancy_grid, \n",
    "                            (frame_shape[1], frame_shape[0]), \n",
    "                            interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Apply Gaussian blur for smooth heatmap\n",
    "        heatmap = cv2.GaussianBlur(heatmap, (51, 51), 0)\n",
    "        \n",
    "        # Normalize and apply colormap\n",
    "        if heatmap.max() > 0:\n",
    "            heatmap_colored = apply_colormap_to_heatmap(heatmap)\n",
    "        else:\n",
    "            heatmap_colored = np.zeros(frame_shape, dtype=np.uint8)\n",
    "        \n",
    "        return heatmap_colored\n",
    "    \n",
    "    def calculate_optical_flow(self, gray_frame):\n",
    "        \"\"\"Calculate dense optical flow\"\"\"\n",
    "        if self.prev_gray is None:\n",
    "            self.prev_gray = gray_frame\n",
    "            return None\n",
    "        \n",
    "        # Farneback optical flow\n",
    "        flow = cv2.calcOpticalFlowFarneback(\n",
    "            self.prev_gray, gray_frame,\n",
    "            None, \n",
    "            pyr_scale=0.5,\n",
    "            levels=3,\n",
    "            winsize=15,\n",
    "            iterations=3,\n",
    "            poly_n=5,\n",
    "            poly_sigma=1.2,\n",
    "            flags=0\n",
    "        )\n",
    "        \n",
    "        self.prev_gray = gray_frame\n",
    "        return flow\n",
    "    \n",
    "    def visualize_flow(self, flow, frame_shape):\n",
    "        \"\"\"Visualize optical flow as HSV\"\"\"\n",
    "        if flow is None:\n",
    "            return np.zeros(frame_shape, dtype=np.uint8)\n",
    "        \n",
    "        magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "        \n",
    "        hsv = np.zeros(frame_shape, dtype=np.uint8)\n",
    "        hsv[..., 0] = angle * 180 / np.pi / 2  # Hue = direction\n",
    "        hsv[..., 1] = 255  # Saturation\n",
    "        hsv[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        \n",
    "        flow_bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        return flow_bgr\n",
    "    \n",
    "    def check_overcrowding(self):\n",
    "        \"\"\"Check for overcrowded zones\"\"\"\n",
    "        alerts = []\n",
    "        \n",
    "        for i in range(self.grid_rows):\n",
    "            for j in range(self.grid_cols):\n",
    "                count = self.occupancy_grid[i, j]\n",
    "                \n",
    "                # Calculate area in square meters\n",
    "                cell_area_pixels = self.cell_width * self.cell_height\n",
    "                cell_area_m2 = cell_area_pixels / (self.pixels_per_meter ** 2)\n",
    "                \n",
    "                # Calculate density (persons per m¬≤)\n",
    "                density = count / cell_area_m2 if cell_area_m2 > 0 else 0\n",
    "                \n",
    "                if density > CONFIG['DENSITY_CRITICAL']:\n",
    "                    alerts.append({\n",
    "                        'zone': (i, j),\n",
    "                        'density': density,\n",
    "                        'count': int(count),\n",
    "                        'level': 'CRITICAL'\n",
    "                    })\n",
    "        \n",
    "        return alerts\n",
    "    \n",
    "    def reset_grid(self):\n",
    "        \"\"\"Reset occupancy grid\"\"\"\n",
    "        self.occupancy_grid.fill(0)\n",
    "\n",
    "print(\"‚úÖ Crowd density analyzer defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2225be66-b947-4e6e-9886-1e94e2c9220c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Abandoned luggage detector defined!\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# ABANDONED LUGGAGE DETECTOR\n",
    "# ================================\n",
    "\n",
    "class AbandonedLuggageDetector:\n",
    "    \"\"\"Detect abandoned luggage\"\"\"\n",
    "    \n",
    "    def __init__(self, distance_threshold=150, time_threshold=30, fps=30):\n",
    "        self.distance_threshold = distance_threshold\n",
    "        self.time_threshold = time_threshold\n",
    "        self.fps = fps\n",
    "        \n",
    "        # Track luggage and their owners\n",
    "        self.luggage_tracks = {}  # {luggage_id: {'owner_id': None, 'frames_alone': 0, ...}}\n",
    "        self.owner_luggage_pairs = {}  # {owner_id: [luggage_ids]}\n",
    "        \n",
    "        self.abandoned_alerts = []\n",
    "        \n",
    "    def update(self, person_tracks, luggage_tracks, frame_count):\n",
    "        \"\"\"\n",
    "        Update abandoned luggage detection\n",
    "        \n",
    "        Args:\n",
    "            person_tracks: List of (track_id, bbox, class)\n",
    "            luggage_tracks: List of (track_id, bbox, class)\n",
    "            frame_count: Current frame number\n",
    "        \"\"\"\n",
    "        # Extract centers\n",
    "        person_centers = {tid: get_center(bbox) for tid, bbox, _ in person_tracks}\n",
    "        luggage_centers = {tid: get_center(bbox) for tid, bbox, _ in luggage_tracks}\n",
    "        \n",
    "        # Associate luggage with nearest person\n",
    "        for lug_id, lug_center in luggage_centers.items():\n",
    "            # Initialize luggage track if new\n",
    "            if lug_id not in self.luggage_tracks:\n",
    "                self.luggage_tracks[lug_id] = {\n",
    "                    'owner_id': None,\n",
    "                    'frames_alone': 0,\n",
    "                    'first_seen': frame_count,\n",
    "                    'last_owner_frame': frame_count,\n",
    "                    'position': lug_center,\n",
    "                    'abandoned': False\n",
    "                }\n",
    "            \n",
    "            # Find nearest person\n",
    "            min_distance = float('inf')\n",
    "            nearest_person = None\n",
    "            \n",
    "            for person_id, person_center in person_centers.items():\n",
    "                dist = euclidean_distance(lug_center, person_center)\n",
    "                if dist < min_distance:\n",
    "                    min_distance = dist\n",
    "                    nearest_person = person_id\n",
    "            \n",
    "            # Update luggage track\n",
    "            luggage_info = self.luggage_tracks[lug_id]\n",
    "            luggage_info['position'] = lug_center\n",
    "            \n",
    "            if min_distance < self.distance_threshold:\n",
    "                # Luggage has owner nearby\n",
    "                luggage_info['owner_id'] = nearest_person\n",
    "                luggage_info['frames_alone'] = 0\n",
    "                luggage_info['last_owner_frame'] = frame_count\n",
    "            else:\n",
    "                # Luggage is alone\n",
    "                luggage_info['frames_alone'] += 1\n",
    "                \n",
    "                # Check if abandoned (alone for threshold duration)\n",
    "                frames_threshold = self.time_threshold * self.fps / CONFIG['PROCESS_EVERY_N_FRAMES']\n",
    "                \n",
    "                if luggage_info['frames_alone'] > frames_threshold and not luggage_info['abandoned']:\n",
    "                    luggage_info['abandoned'] = True\n",
    "                    \n",
    "                    # Create alert\n",
    "                    alert = {\n",
    "                        'luggage_id': lug_id,\n",
    "                        'position': lug_center,\n",
    "                        'duration': luggage_info['frames_alone'] / (self.fps / CONFIG['PROCESS_EVERY_N_FRAMES']),\n",
    "                        'frame': frame_count,\n",
    "                        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                    }\n",
    "                    self.abandoned_alerts.append(alert)\n",
    "                    print(f\"üö® ALERT: Abandoned luggage detected! ID: {lug_id}, Position: {lug_center}\")\n",
    "        \n",
    "        # Clean up old tracks\n",
    "        active_luggage_ids = set(luggage_centers.keys())\n",
    "        ids_to_remove = [lid for lid in self.luggage_tracks.keys() \n",
    "                        if lid not in active_luggage_ids]\n",
    "        for lid in ids_to_remove:\n",
    "            del self.luggage_tracks[lid]\n",
    "    \n",
    "    def get_abandoned_luggage(self):\n",
    "        \"\"\"Get list of currently abandoned luggage\"\"\"\n",
    "        return [(lid, info['position']) \n",
    "                for lid, info in self.luggage_tracks.items() \n",
    "                if info['abandoned']]\n",
    "    \n",
    "    def get_all_alerts(self):\n",
    "        \"\"\"Get all abandoned luggage alerts\"\"\"\n",
    "        return self.abandoned_alerts\n",
    "\n",
    "print(\"‚úÖ Abandoned luggage detector defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02f2f0d4-f297-423d-b0e8-fa5434e13e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing Airport Security System...\n",
      "üì¶ Loading yolov8n.pt...\n",
      "‚úÖ Model loaded!\n",
      "üìπ Video: 3840x2160 @ 30 FPS\n",
      "üìä Total frames: 222\n",
      "üìä Grid initialized: 5x5\n",
      "üìè Cell size: 768x432 pixels\n",
      "‚úÖ System initialized!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# INITIALIZE SYSTEM\n",
    "# ================================\n",
    "\n",
    "print(\"üöÄ Initializing Airport Security System...\")\n",
    "\n",
    "# Load YOLO model\n",
    "print(f\"üì¶ Loading {CONFIG['MODEL']}...\")\n",
    "model = YOLO(CONFIG['MODEL'])\n",
    "print(\"‚úÖ Model loaded!\")\n",
    "\n",
    "# Open video\n",
    "cap = cv2.VideoCapture(CONFIG['VIDEO_PATH'])\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(f\"‚ùå Cannot open video: {CONFIG['VIDEO_PATH']}\")\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(f\"üìπ Video: {frame_width}x{frame_height} @ {fps} FPS\")\n",
    "print(f\"üìä Total frames: {total_frames}\")\n",
    "\n",
    "# Initialize video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(CONFIG['OUTPUT_PATH'], fourcc, fps, \n",
    "                      (frame_width, frame_height))\n",
    "\n",
    "# Initialize components\n",
    "tracker = SimpleTracker(\n",
    "    max_age=CONFIG['MAX_AGE'],\n",
    "    min_hits=CONFIG['MIN_HITS'],\n",
    "    iou_threshold=CONFIG['IOU_THRESHOLD']\n",
    ")\n",
    "\n",
    "crowd_analyzer = CrowdDensityAnalyzer(\n",
    "    frame_shape=(frame_height, frame_width, 3),\n",
    "    grid_size=CONFIG['GRID_SIZE'],\n",
    "    pixels_per_meter=CONFIG['PIXELS_PER_METER']\n",
    ")\n",
    "\n",
    "abandoned_detector = AbandonedLuggageDetector(\n",
    "    distance_threshold=CONFIG['OWNER_DISTANCE_THRESHOLD'],\n",
    "    time_threshold=CONFIG['STATIONARY_TIME'],\n",
    "    fps=fps\n",
    ")\n",
    "\n",
    "# Storage for trajectories\n",
    "trajectories = defaultdict(lambda: deque(maxlen=30))\n",
    "\n",
    "# Statistics\n",
    "stats = {\n",
    "    'total_persons': 0,\n",
    "    'total_luggage': 0,\n",
    "    'overcrowding_alerts': 0,\n",
    "    'abandoned_alerts': 0,\n",
    "    'frames_processed': 0\n",
    "}\n",
    "\n",
    "print(\"‚úÖ System initialized!\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60ec4028-45af-4904-9bc2-042e51387ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Progress: 94.6% | Frame: 210/222\n",
      "‚ö° Processing Speed: 0.5 FPS\n",
      "üë• Current Persons: 5\n",
      "üß≥ Current Luggage: 0\n",
      "üö® Abandoned Alerts: 0\n",
      "‚ö†Ô∏è  Overcrowding Alerts: 0\n",
      "\n",
      "============================================================\n",
      "‚úÖ Processing complete!\n",
      "‚è±Ô∏è  Total time: 404.75 seconds\n",
      "‚ö° Average FPS: 0.55\n",
      "üíæ Output saved to: output_video.mp4\n",
      "üìä Final Stats:\n",
      "   - Frames processed: 222\n",
      "   - Abandoned luggage alerts: 0\n",
      "   - Overcrowding alerts: 0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# MAIN PROCESSING LOOP\n",
    "# ================================\n",
    "\n",
    "print(\"üé¨ Starting video processing...\")\n",
    "print(\"Press 'q' to stop early\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "frame_count = 0\n",
    "start_time = time.time()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_count += 1\n",
    "    \n",
    "    # Process every N frames\n",
    "    if frame_count % CONFIG['PROCESS_EVERY_N_FRAMES'] != 0:\n",
    "        continue\n",
    "    \n",
    "    # Create copies for different visualizations\n",
    "    display_frame = frame.copy()\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 1: DETECTION\n",
    "    # ============================================\n",
    "    results = model(frame, conf=CONFIG['CONFIDENCE_THRESHOLD'], verbose=False)\n",
    "    \n",
    "    detections_persons = []\n",
    "    detections_luggage = []\n",
    "    \n",
    "    if len(results) > 0 and results[0].boxes is not None:\n",
    "        boxes = results[0].boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            conf = box.conf[0].cpu().numpy()\n",
    "            cls = int(box.cls[0].cpu().numpy())\n",
    "            \n",
    "            detection = [x1, y1, x2, y2, conf, cls]\n",
    "            \n",
    "            if cls == CONFIG['PERSON_CLASS']:\n",
    "                detections_persons.append(detection)\n",
    "            elif cls in CONFIG['LUGGAGE_CLASSES']:\n",
    "                detections_luggage.append(detection)\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 2: TRACKING\n",
    "    # ============================================\n",
    "    # Track persons\n",
    "    person_tracks = tracker.update(detections_persons)\n",
    "    \n",
    "    # Track luggage (separate tracker instance would be better, but simplifying)\n",
    "    luggage_tracks = []\n",
    "    for det in detections_luggage:\n",
    "        luggage_tracks.append((len(luggage_tracks), det[:4], int(det[5])))\n",
    "    \n",
    "    stats['total_persons'] = len(person_tracks)\n",
    "    stats['total_luggage'] = len(luggage_tracks)\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 3: CROWD DENSITY ANALYSIS\n",
    "    # ============================================\n",
    "    crowd_analyzer.reset_grid()\n",
    "    \n",
    "    person_centers = []\n",
    "    for track_id, bbox, cls in person_tracks:\n",
    "        center = get_center(bbox)\n",
    "        person_centers.append(center)\n",
    "        trajectories[track_id].append(center)\n",
    "        crowd_analyzer.update_density([center])\n",
    "    \n",
    "    # Check overcrowding\n",
    "    overcrowding_alerts = crowd_analyzer.check_overcrowding()\n",
    "    if overcrowding_alerts:\n",
    "        stats['overcrowding_alerts'] += len(overcrowding_alerts)\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 4: OPTICAL FLOW\n",
    "    # ============================================\n",
    "    flow = None\n",
    "    if CONFIG['ENABLE_OPTICAL_FLOW']:\n",
    "        flow = crowd_analyzer.calculate_optical_flow(gray_frame)\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 5: ABANDONED LUGGAGE DETECTION\n",
    "    # ============================================\n",
    "    abandoned_detector.update(person_tracks, luggage_tracks, frame_count)\n",
    "    abandoned_luggage = abandoned_detector.get_abandoned_luggage()\n",
    "    stats['abandoned_alerts'] = len(abandoned_detector.get_all_alerts())\n",
    "    \n",
    "    # ============================================\n",
    "    # VISUALIZATION\n",
    "    # ============================================\n",
    "    \n",
    "    # Draw person bounding boxes and IDs\n",
    "    for track_id, bbox, cls in person_tracks:\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        draw_text_with_background(display_frame, f\"ID:{track_id}\", \n",
    "                                  (x1, y1-10), bg_color=(0, 255, 0))\n",
    "    \n",
    "    # Draw luggage bounding boxes\n",
    "    for lug_id, bbox, cls in luggage_tracks:\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        color = (0, 165, 255)  # Orange for luggage\n",
    "        cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 2)\n",
    "        draw_text_with_background(display_frame, \"Luggage\", \n",
    "                                  (x1, y1-10), bg_color=color)\n",
    "    \n",
    "    # Draw abandoned luggage alerts\n",
    "    for lug_id, position in abandoned_luggage:\n",
    "        cx, cy = position\n",
    "        cv2.circle(display_frame, (cx, cy), 50, (0, 0, 255), 3)\n",
    "        draw_text_with_background(display_frame, \"ABANDONED!\", \n",
    "                                  (cx-40, cy-60), \n",
    "                                  font_scale=0.8, \n",
    "                                  bg_color=(0, 0, 255))\n",
    "        # Flashing effect\n",
    "        if frame_count % 20 < 10:\n",
    "            cv2.circle(display_frame, (cx, cy), 55, (0, 0, 255), 5)\n",
    "    \n",
    "    # Draw trajectories\n",
    "    if CONFIG['SHOW_TRAJECTORIES']:\n",
    "        for track_id, trail in trajectories.items():\n",
    "            if len(trail) > 1:\n",
    "                points = np.array(trail, dtype=np.int32)\n",
    "                cv2.polylines(display_frame, [points], False, (255, 0, 255), 2)\n",
    "    \n",
    "    # Draw overcrowding alerts\n",
    "    for alert in overcrowding_alerts:\n",
    "        zone_i, zone_j = alert['zone']\n",
    "        x = zone_j * crowd_analyzer.cell_width\n",
    "        y = zone_i * crowd_analyzer.cell_height\n",
    "        cv2.rectangle(display_frame, \n",
    "                     (x, y), \n",
    "                     (x + crowd_analyzer.cell_width, y + crowd_analyzer.cell_height),\n",
    "                     (0, 0, 255), 3)\n",
    "        draw_text_with_background(display_frame, \n",
    "                                 f\"OVERCROWDING! {alert['count']} people\", \n",
    "                                 (x+10, y+30),\n",
    "                                 bg_color=(0, 0, 255))\n",
    "    \n",
    "    # Add statistics overlay\n",
    "    stats_text = [\n",
    "        f\"Frame: {frame_count}/{total_frames}\",\n",
    "        f\"Persons: {stats['total_persons']}\",\n",
    "        f\"Luggage: {stats['total_luggage']}\",\n",
    "        f\"Overcrowding Alerts: {stats['overcrowding_alerts']}\",\n",
    "        f\"Abandoned Alerts: {stats['abandoned_alerts']}\"\n",
    "    ]\n",
    "    \n",
    "    y_offset = 30\n",
    "    for i, text in enumerate(stats_text):\n",
    "        draw_text_with_background(display_frame, text, (10, y_offset + i*30),\n",
    "                                 font_scale=0.7, bg_color=(0, 0, 0))\n",
    "    \n",
    "    # Write frame to output video\n",
    "    out.write(display_frame)\n",
    "    stats['frames_processed'] += 1\n",
    "    \n",
    "    # Display progress every 30 frames\n",
    "    if frame_count % 30 == 0:\n",
    "        progress = (frame_count / total_frames) * 100\n",
    "        elapsed = time.time() - start_time\n",
    "        fps_processing = frame_count / elapsed if elapsed > 0 else 0\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        print(f\"‚è≥ Progress: {progress:.1f}% | Frame: {frame_count}/{total_frames}\")\n",
    "        print(f\"‚ö° Processing Speed: {fps_processing:.1f} FPS\")\n",
    "        print(f\"üë• Current Persons: {stats['total_persons']}\")\n",
    "        print(f\"üß≥ Current Luggage: {stats['total_luggage']}\")\n",
    "        print(f\"üö® Abandoned Alerts: {stats['abandoned_alerts']}\")\n",
    "        print(f\"‚ö†Ô∏è  Overcrowding Alerts: {stats['overcrowding_alerts']}\")\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Processing complete!\")\n",
    "print(f\"‚è±Ô∏è  Total time: {elapsed_time:.2f} seconds\")\n",
    "print(f\"‚ö° Average FPS: {stats['frames_processed']/elapsed_time:.2f}\")\n",
    "print(f\"üíæ Output saved to: {CONFIG['OUTPUT_PATH']}\")\n",
    "print(f\"üìä Final Stats:\")\n",
    "print(f\"   - Frames processed: {stats['frames_processed']}\")\n",
    "print(f\"   - Abandoned luggage alerts: {stats['abandoned_alerts']}\")\n",
    "print(f\"   - Overcrowding alerts: {stats['overcrowding_alerts']}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425d6b72-8b1b-4a92-b962-a9375688ba57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
